{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7690db",
   "metadata": {},
   "source": [
    "# andre marroquin\n",
    "# rodrigo mansilla\n",
    "# sergio orellana \n",
    "# carlos valladares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f179e2",
   "metadata": {},
   "source": [
    "# Proyecto 2 — Data Science\n",
    "### link repo: https://github.com/mar22266/PY2-DS/tree/Resultados-Parciales-y-Visualizaciones-Est%C3%A1ticas\n",
    "\n",
    "branch: Resultados Parciales y Visualizaciones Estáticas\n",
    "\n",
    "## Fase 2: Investigación de modelos, selección, entrenamiento, evaluación y discusión\n",
    "\n",
    "**Reto:** CGIAR – Ojos en el Terreno (detección de daños en cultivos)\n",
    "\n",
    "**Objetivo de esta fase.** Partiendo del EDA, investigar algoritmos, seleccionar candidatos, construir varios modelos que predigan `EXTENT` (severidad % por fila (ID, DAMAGE)), evaluarlos con métricas apropiadas para **regresión**, comparar resultados, justificar la selección final y generar visualizaciones estáticas.\n",
    "\n",
    "**Tarea de modelado.** Cada fila representa un par `(ID, DAMAGE)` con metadatos (`season`, `growth_stage`, `filename`) y el objetivo `EXTENT` (0–100 en train; ausente en test). En test se debe predecir `EXTENT` por fila, y luego formatear el archivo de envío siguiendo `SampleSubmission.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4ab74",
   "metadata": {},
   "source": [
    "## Configuración, imports y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a191450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUTAS OK: True True True\n"
     ]
    }
   ],
   "source": [
    "# importaciones de librerias\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Rutas\n",
    "DATA_DIR = Path(\".\")\n",
    "TRAIN_CSV = DATA_DIR / \"Train.csv\"\n",
    "TEST_CSV = DATA_DIR / \"Test.csv\"\n",
    "SAMPLE_CSV = DATA_DIR / \"SampleSubmission.csv\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"./outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "print(\"RUTAS OK:\", TRAIN_CSV.exists(), TEST_CSV.exists(), SAMPLE_CSV.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f3af2",
   "metadata": {},
   "source": [
    "## Selección de algoritmos a probar (justificación)\n",
    "\n",
    "Como la variable objetivo `EXTENT` es **continua (0–100)** por `(ID, DAMAGE)`, se plantean **modelos de regresión tabular** con metadatos y rasgos derivados del `filename`:\n",
    "\n",
    "1) **Ridge Regression** (lineal regularizada): buen baseline, interpretable; sirve para detectar relaciones lineales tras one-hot y scaling.  \n",
    "2) **Random Forest Regressor**: no lineal, robusto a outlier*, captura interacciones y no exige scaling.  \n",
    "3) **HistGradientBoostingRegressor** (sklearn): *boosting* eficiente, suele mejorar MAE/RMSE en tabular con variables categóricas codificadas.\n",
    "\n",
    "Todos evaluados con **GroupKFold por `ID`** para evitar *leakage* entre filas del mismo ID (pues cada imagen aporta varias filas, una por `DAMAGE`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6921414",
   "metadata": {},
   "source": [
    "## Carga y verificación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3301ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                        filename growth_stage damage  extent  \\\n",
      "0  ID_1S8OOWQYCB  L427F01330C01S03961Rp02052.jpg            S     WD       0   \n",
      "1  ID_0MD959MIZ0      L1083F00930C39S12674Ip.jpg            V      G       0   \n",
      "2  ID_JRJCI4Q11V      24_initial_1_1463_1463.JPG            V      G       0   \n",
      "\n",
      "   season  \n",
      "0  SR2020  \n",
      "1  SR2021  \n",
      "2  LR2020  \n",
      "              ID                         filename growth_stage damage  season\n",
      "0  ID_ROOWKB90UZ   L122F00315C01S02151Rp04021.jpg            V     WD  SR2020\n",
      "1  ID_PTEDRY0CYM  L1089F03254C01S08845Rp25119.jpg            F     WD  LR2021\n",
      "2  ID_5WJXDV96R4   L365F01913C39S12578Rp42918.jpg            V     WD  SR2021\n",
      "              ID  extent\n",
      "0  ID_KJ12GE2U80       0\n",
      "1  ID_W33POE3DBX       0\n",
      "2  ID_1DZ7VKQTS9       0\n",
      "shapes: (26068, 6) (8663, 5) (8663, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_CSV)\n",
    "test = pd.read_csv(TEST_CSV)\n",
    "sample = pd.read_csv(SAMPLE_CSV)\n",
    "\n",
    "print(train.head(3))\n",
    "print(test.head(3))\n",
    "print(sample.head(3))\n",
    "print(\"shapes:\", train.shape, test.shape, sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a084581",
   "metadata": {},
   "source": [
    "## Preprocesamiento columnas, mapeos, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id damage  season stage_code  has_jpg  has_jpeg  len_name  \\\n",
      "0  ID_1S8OOWQYCB     WD  SR2020          S        1         0        30   \n",
      "1  ID_0MD959MIZ0      G  SR2021          V        1         0        26   \n",
      "2  ID_JRJCI4Q11V      G  LR2020          V        1         0        26   \n",
      "\n",
      "   digits_sum  extent  \n",
      "0        7771       0  \n",
      "1       14726       0  \n",
      "2        2951       0  \n",
      "              id damage  season stage_code  has_jpg  has_jpeg  len_name  \\\n",
      "0  ID_ROOWKB90UZ     WD  SR2020          V        1         0        30   \n",
      "1  ID_PTEDRY0CYM     WD  LR2021          F        1         0        31   \n",
      "2  ID_5WJXDV96R4     WD  SR2021          V        1         0        30   \n",
      "\n",
      "   digits_sum  \n",
      "0        6610  \n",
      "1       38308  \n",
      "2       57813  \n"
     ]
    }
   ],
   "source": [
    "# Normaliza códigos de temporada\n",
    "def normalize_season(s: str) -> str:\n",
    "    if pd.isna(s): \n",
    "        return \"UNKNOWN\"\n",
    "    t = str(s).upper().strip().replace(\" \", \"\")\n",
    "    t = re.sub(r\"[^A-Z0-9]\", \"\", t)\n",
    "    return t\n",
    "\n",
    "_STAGE_MAP = {\n",
    "    \"F\": \"F\", \"FLOWERING\": \"F\",\n",
    "    \"M\": \"M\", \"MATURITY\": \"M\",\n",
    "    \"S\": \"S\", \"SOWING\": \"S\",\n",
    "    \"V\": \"V\", \"VEGETATIVE\": \"V\"\n",
    "}\n",
    "\n",
    "# Normaliza códigos de etapa de crecimiento\n",
    "def normalize_stage(s: str) -> str:\n",
    "    if pd.isna(s): \n",
    "        return \"UNK\"\n",
    "    t = str(s).upper().strip()\n",
    "    return _STAGE_MAP.get(t, t if t in {\"F\",\"M\",\"S\",\"V\"} else \"UNK\")\n",
    "\n",
    "def filename_features(fname: str) -> Dict[str, str|int]:\n",
    "    \"\"\"\n",
    "    Heurística ligera para extraer rasgos del 'filename':\n",
    "    - prefijos con L###F####C##S#####...\n",
    "    - números grandes como proxy de sitio/cámara/posición\n",
    "    \"\"\"\n",
    "    d = {\"has_jpg\": 0, \"has_jpeg\": 0, \"len_name\": 0, \"digits_sum\": 0}\n",
    "    if not isinstance(fname, str):\n",
    "        return d\n",
    "    name = fname.strip()\n",
    "    d[\"has_jpg\"] = int(name.lower().endswith(\".jpg\"))\n",
    "    d[\"has_jpeg\"] = int(name.lower().endswith(\".jpeg\"))\n",
    "    d[\"len_name\"] = len(name)\n",
    "    digits = re.findall(r\"\\d+\", name)\n",
    "    d[\"digits_sum\"] = int(np.sum([int(x) for x in digits])) if digits else 0\n",
    "    return d\n",
    "\n",
    "# Aplicar preprocesamiento a DataFrame\n",
    "def apply_preprocessing(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # Asegurar columnas esperadas\n",
    "    expected = {\"ID\",\"filename\",\"growth_stage\",\"damage\",\"season\"}\n",
    "    missing = expected - set(out.columns.str.lower())\n",
    "    # Normaliza nombres\n",
    "    out.columns = [c.lower() for c in out.columns]\n",
    "    # Re-chequeo\n",
    "    if not {\"id\",\"filename\",\"growth_stage\",\"damage\",\"season\"}.issubset(set(out.columns)):\n",
    "        raise ValueError(\"Faltan columnas clave después de normalizar nombres.\")\n",
    "\n",
    "    # Normalizaciones\n",
    "    out[\"season\"] = out[\"season\"].map(normalize_season)\n",
    "    out[\"stage_code\"] = out[\"growth_stage\"].map(normalize_stage)\n",
    "    out[\"damage\"] = out[\"damage\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # EXTENT: si existe, asegurar rango 0..100\n",
    "    if \"extent\" in out.columns:\n",
    "        out[\"extent\"] = pd.to_numeric(out[\"extent\"], errors=\"coerce\").fillna(0.0).clip(0, 100)\n",
    "\n",
    "    # Rasgos del filename\n",
    "    feats = out[\"filename\"].apply(filename_features).apply(pd.Series)\n",
    "    out = pd.concat([out, feats], axis=1)\n",
    "\n",
    "    # Mantener solo columnas útiles\n",
    "    keep_cols = [\"id\",\"damage\",\"season\",\"stage_code\",\"has_jpg\",\"has_jpeg\",\"len_name\",\"digits_sum\"]\n",
    "    if \"extent\" in out.columns:\n",
    "        keep_cols.append(\"extent\")\n",
    "    return out[keep_cols]\n",
    "\n",
    "train_clean = apply_preprocessing(train, is_train=True)\n",
    "test_clean  = apply_preprocessing(test,  is_train=False)\n",
    "\n",
    "print(train_clean.head(3))\n",
    "print(test_clean.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bd2d1",
   "metadata": {},
   "source": [
    "## Partición con GroupKFold (evitar leakage por ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS: 5\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para modelado\n",
    "X_cols_cat = [\"damage\",\"season\",\"stage_code\"]\n",
    "X_cols_num = [\"has_jpg\",\"has_jpeg\",\"len_name\",\"digits_sum\"]\n",
    "y_col = \"extent\"\n",
    "\n",
    "# asseertions\n",
    "assert y_col in train_clean.columns, \"La columna 'extent' debe existir en train.\"\n",
    "\n",
    "# limpiar datos\n",
    "X = train_clean[X_cols_cat + X_cols_num].copy()\n",
    "y = train_clean[y_col].copy()\n",
    "groups = train_clean[\"id\"].astype(str).values  \n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_indices = list(gkf.split(X, y, groups=groups))\n",
    "print(\"FOLDS:\", len(fold_indices))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
